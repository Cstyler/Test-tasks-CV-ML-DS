{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68e3d945-bed1-4c36-8206-b890a42973c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import string\n",
    "from rnn import forward_pass, backward_pass, create_datasets, optimize_sgd, init_rnn, one_hot_encode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74033484-8d52-45f0-8257-fc91135699fc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Parse text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4d9195f-c942-4ece-9769-051cad7bdca8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('train.txt', 'r') as _file:\n",
    "    train_text = _file.read()\n",
    "train_words = []\n",
    "strip_str = string.punctuation + string.whitespace\n",
    "for line in train_text.split('\\n'):\n",
    "    for sentence in line.split('.'):\n",
    "        words = [x.lower().strip(strip_str) for x in sentence.split() if x != '—']\n",
    "        train_words.extend(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714d8689-48e8-43ba-baf0-2c5e0e31e8ca",
   "metadata": {},
   "source": [
    "## Set hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5df79c3-e5cf-4793-acdb-6db3aca2af3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of input/target sequences\n",
    "window_size = 3\n",
    "# size of word embedding\n",
    "embedding_dim = 128\n",
    "p_train = 0.8\n",
    "# num of training epochs\n",
    "num_epochs = 30\n",
    "# size of hidden state\n",
    "hidden_size = 256\n",
    "# learning rate of SGD optimizer\n",
    "lr = .2\n",
    "# gradient norm clipping\n",
    "clip_norm = .8\n",
    "# print loss every n epochs\n",
    "print_loss_n = 2\n",
    "# wait n epochs if val loss doesn't improve\n",
    "patience = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96915ec7-2197-47fc-8c8c-2b96a2c95546",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Prepare input and target arrays, split to train, val, test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ddad06e-972f-43bc-9438-3ee5f7efb50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_idx = {}\n",
    "idx_to_word = {}\n",
    "word_to_idx = {word: i for i, word in enumerate(sorted(set(train_words)))}\n",
    "idx_to_word = {i: word for word, i in word_to_idx.items()}\n",
    "data_x = []\n",
    "data_y = []\n",
    "n = len(train_words)\n",
    "vocab_size = len(word_to_idx)\n",
    "for i in range(0, n - window_size * 2, 1):\n",
    "    rb = i + window_size\n",
    "    words_x = train_words[i:rb]\n",
    "    # input array of indexes of words\n",
    "    sample_x = np.array([word_to_idx[word] for word in words_x])\n",
    "    words_y = train_words[rb:rb + window_size]\n",
    "    # one-hot encoded target array\n",
    "    sample_y = np.array([one_hot_encode(word_to_idx[word], vocab_size) for word in words_y])\n",
    "    data_x.append(sample_x)\n",
    "    data_y.append(sample_y)\n",
    "data_x = np.array(data_x)\n",
    "data_y = np.array(data_y)\n",
    "p_val = .5 - p_train / 2\n",
    "training_set, validation_set, test_set = create_datasets(data_x, data_y, p_train, p_val, p_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185d400b-0434-478a-b2e3-223dd591e572",
   "metadata": {},
   "source": [
    "## Check dataset inputs and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "716f7b79-9273-4288-8cb6-6a319dfdb146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['наших', 'ограничений', 'пусть']\n",
      "['позитив', 'будет', 'вашим']\n"
     ]
    }
   ],
   "source": [
    "data_x, data_y = list(zip(*test_set))\n",
    "i = 10\n",
    "print([idx_to_word[idx] for idx in data_x[i]])\n",
    "print([idx_to_word[np.argmax(idx)] for idx in data_y[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e1bdea-df75-4bc7-a96d-5582b0dc28c3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71c4304-f345-4b1e-b632-03d6eb13dd5e",
   "metadata": {},
   "source": [
    "Я использовал алгоритм оптимизации SGD с gradient clipping, чтобы избежать проблему исчезающих градиентов. Обучение останавливается, если функция ошибки на валидационном датасете не улучшается `patience` эпох подряд"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a17b73d-c5fe-46f4-aa02-4548418210ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, training loss: 0.021, validation loss: 0.024\n",
      "Epoch 2, training loss: 0.01, validation loss: 0.016\n",
      "Epoch 4, training loss: 0.005, validation loss: 0.013\n",
      "Epoch 6, training loss: 0.004, validation loss: 0.011\n",
      "Epoch 8, training loss: 0.003, validation loss: 0.011\n"
     ]
    }
   ],
   "source": [
    "train_num = len(training_set)\n",
    "val_num = len(validation_set)\n",
    "\n",
    "# Initialize a network\n",
    "params = init_rnn(hidden_size, vocab_size, embedding_dim)\n",
    "\n",
    "# Initialize hidden state as zeros\n",
    "hidden_state = np.zeros((hidden_size, 1))\n",
    "\n",
    "# Track loss\n",
    "training_loss, validation_loss = [], []\n",
    "num_no_improving = 0\n",
    "for i in range(num_epochs):\n",
    "    epoch_training_loss = 0\n",
    "    epoch_validation_loss = 0\n",
    "\n",
    "    for inputs, targets in validation_set:\n",
    "        # Re-initialize hidden state\n",
    "        hidden_state = np.zeros_like(hidden_state)\n",
    "        outputs, hidden_states = forward_pass(inputs, hidden_state, params)\n",
    "        loss, _ = backward_pass(inputs, outputs, hidden_states, targets, params)\n",
    "        # Update loss\n",
    "        epoch_validation_loss += loss\n",
    "\n",
    "    for inputs, targets in training_set:\n",
    "        # Re-initialize hidden state\n",
    "        hidden_state = np.zeros_like(hidden_state)\n",
    "        outputs, hidden_states = forward_pass(inputs, hidden_state, params)\n",
    "        loss, grads = backward_pass(inputs, outputs, hidden_states, targets, params)\n",
    "        if np.isnan(loss):\n",
    "            raise ValueError('Gradients have vanished!')\n",
    "        # Update parameters\n",
    "        params = optimize_sgd(params, grads, lr, clip_norm)\n",
    "        # Update loss\n",
    "        epoch_training_loss += loss\n",
    "        \n",
    "    # Save loss for plot\n",
    "    training_loss.append(epoch_training_loss / train_num)\n",
    "    validation_loss.append(epoch_validation_loss / val_num)\n",
    "    # Print loss every N epochs\n",
    "    if i % print_loss_n == 0:\n",
    "        print(f'Epoch {i}, training loss: {round(training_loss[-1], 3)}, validation loss: {round(validation_loss[-1], 3)}')\n",
    "    # stop if val loss didn't improve from previous epoch\n",
    "    if len(validation_loss) > 2 and validation_loss[-2] < validation_loss[-1]:\n",
    "        num_no_improving += 1\n",
    "    else:\n",
    "        num_no_improving = 0\n",
    "    if num_no_improving >= patience:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d697ba2b-897f-4a6a-a666-583192a59f98",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Inference of the model on train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2a59b6a5-145a-474b-9d79-265372294b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_model_and_print(inputs, targets):\n",
    "    # Initialize hidden state as zeros\n",
    "    hidden_state = np.zeros((hidden_size, 1))\n",
    "\n",
    "    # Forward pass\n",
    "    outputs, hidden_states = forward_pass(inputs, hidden_state, params)\n",
    "    input_sentence = [idx_to_word[x] for x in inputs]\n",
    "    output_sentence = [idx_to_word[np.argmax(x)] for x in outputs]\n",
    "    target_sentence = [idx_to_word[np.argmax(x)] for x in targets]\n",
    "    print('Input sequence:', input_sentence)\n",
    "    print('Target sequence:', target_sentence)\n",
    "    print('Predicted sequence:', output_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "da9cf6d8-0717-421c-be08-ad384a023b6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sequence: ['привнести', 'позитивную', 'энергию']\n",
      "Target sequence: ['в', 'нашу', 'повседневную']\n",
      "Predicted sequence: ['в', 'нашу', 'повседневную']\n",
      "Input sequence: ['но', 'вы', 'сможете']\n",
      "Target sequence: ['сделать', 'это', 'чем']\n",
      "Predicted sequence: ['раздвинуть', 'это', 'чем']\n",
      "Input sequence: ['мой', 'опыт', 'никому']\n",
      "Target sequence: ['не', 'нужен', 'вокруг']\n",
      "Predicted sequence: ['не', 'нужен', 'вокруг']\n",
      "Input sequence: ['защитит', 'вас', 'от']\n",
      "Target sequence: ['стрелы', 'негатива', 'если']\n",
      "Predicted sequence: ['стрелы', 'негатива', 'если']\n",
      "Input sequence: ['на', 'своей', 'личности']\n",
      "Target sequence: ['а', 'не', 'на']\n",
      "Predicted sequence: ['наказуема', 'своих', 'на']\n",
      "Input sequence: ['своего', 'сердца', 'верьте']\n",
      "Target sequence: ['что', 'вам', 'суждено']\n",
      "Predicted sequence: ['что', 'вам', 'суждено']\n",
      "Input sequence: ['увидеть', 'как', 'ты']\n",
      "Target sequence: ['становишься', 'сильнее', 'и']\n",
      "Predicted sequence: ['становишься', 'сильнее', 'и']\n",
      "Input sequence: ['конце', 'туннеля', 'есть']\n",
      "Target sequence: ['свет', 'может', 'показаться']\n",
      "Predicted sequence: ['сильных', 'может', 'показаться']\n",
      "Input sequence: ['до', 'добра', 'не']\n",
      "Target sequence: ['доведет', 'большие', 'деньги']\n",
      "Predicted sequence: ['но', 'большие', 'деньги']\n",
      "Input sequence: ['чтобы', 'увидеть', 'как']\n",
      "Target sequence: ['ты', 'становишься', 'сильнее']\n",
      "Predicted sequence: ['результат', 'становишься', 'сильнее']\n",
      "Input sequence: ['вы', 'способны', 'достичь']\n",
      "Target sequence: ['большего', 'чем', 'знаете']\n",
      "Predicted sequence: ['вас', 'чем', 'знаете']\n",
      "Input sequence: ['честные', 'деньги', 'не']\n",
      "Target sequence: ['бывают', 'большими', 'если']\n",
      "Predicted sequence: ['бывают', 'большими', 'если']\n",
      "Input sequence: ['повезет', 'я', 'не']\n",
      "Target sequence: ['могу', 'с', 'этим']\n",
      "Predicted sequence: ['могу', 'с', 'этим']\n",
      "Input sequence: ['своих', 'возможностей', 'ваша']\n",
      "Target sequence: ['жизнь', 'стоит', 'намного']\n",
      "Predicted sequence: ['пядей', 'стоит', 'намного']\n",
      "Input sequence: ['такой', 'бестолковый', 'мне']\n",
      "Target sequence: ['все', 'равно', 'не']\n",
      "Predicted sequence: ['только', 'равно', 'не']\n"
     ]
    }
   ],
   "source": [
    "for i in range(15):\n",
    "    inputs, targets = training_set[i]\n",
    "    inference_model_and_print(inputs, targets)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e941762d-278a-4a7f-bc74-043d4a21a9fc",
   "metadata": {},
   "source": [
    "## Inference of the model on val dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "022a16e6-3fea-435f-9a49-ff800a8dc445",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sequence: ['два', 'варианта', 'быть']\n",
      "Target sequence: ['положительным', 'или', 'отрицательным']\n",
      "Predicted sequence: ['день', 'кто', 'в']\n",
      "Input sequence: ['успешным', 'тяжелые', 'времена']\n",
      "Target sequence: ['часто', 'приводят', 'к']\n",
      "Predicted sequence: ['часто', 'приводят', 'к']\n",
      "Input sequence: ['не', 'всегда', 'приносят']\n",
      "Target sequence: ['рост', 'но', 'без']\n",
      "Predicted sequence: ['а', 'позитив', 'без']\n",
      "Input sequence: ['из', 'тех', 'дней']\n",
      "Target sequence: ['когда', 'не', 'чувствуете']\n",
      "Predicted sequence: ['вещь', 'не', 'чувствуете']\n",
      "Input sequence: ['всегда', 'напоминайте', 'себе']\n",
      "Target sequence: ['что', 'вам', 'не']\n",
      "Predicted sequence: ['самое', 'и', 'и']\n",
      "Input sequence: ['день', 'либо', 'день']\n",
      "Target sequence: ['бежит', 'за', 'тобой']\n",
      "Predicted sequence: ['позитивным', 'не', 'только']\n",
      "Input sequence: ['возможности', 'того', 'что']\n",
      "Target sequence: ['вы', 'планируете', 'делать']\n",
      "Predicted sequence: ['препятствия', 'потому', 'сделать']\n",
      "Input sequence: ['нужна', 'мне', 'всегда']\n",
      "Target sequence: ['не', 'везет', 'меня']\n",
      "Predicted sequence: ['не', 'не', 'вы']\n",
      "Input sequence: ['свет', 'может', 'показаться']\n",
      "Target sequence: ['что', 'добраться', 'до']\n",
      "Predicted sequence: ['а', 'добраться', 'до']\n",
      "Input sequence: ['выбор', 'на', 'всю']\n",
      "Target sequence: ['оставшуюся', 'жизнь', 'не']\n",
      "Predicted sequence: ['и', 'к', 'энергию']\n",
      "Input sequence: ['собой', 'то', 'значит']\n",
      "Target sequence: ['кто-то', 'есть', 'все']\n",
      "Predicted sequence: ['кто-то', 'и', 'если']\n",
      "Input sequence: ['болезней', 'богатство', 'до']\n",
      "Target sequence: ['добра', 'не', 'доведет']\n",
      "Predicted sequence: ['а', 'не', 'но']\n",
      "Input sequence: ['а', 'от', 'всего']\n",
      "Target sequence: ['остального', 'просто', 'отшутиться']\n",
      "Predicted sequence: ['просто', 'просто', 'отшутиться']\n",
      "Input sequence: ['во', 'лбу', 'начальник']\n",
      "Target sequence: ['никогда', 'тебя', 'не']\n",
      "Predicted sequence: ['самая', 'тебя', 'не']\n",
      "Input sequence: ['превращай', 'это', 'во']\n",
      "Target sequence: ['что-то', 'позитивное', 'самая']\n",
      "Predicted sequence: ['печаль', 'позитивное', 'самая']\n"
     ]
    }
   ],
   "source": [
    "for i in range(15):\n",
    "    inputs, targets = validation_set[i]\n",
    "    inference_model_and_print(inputs, targets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21336b83-3f21-419d-be15-6358e8d50f3d",
   "metadata": {},
   "source": [
    "## Inference of the model on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "40e92825-840c-411d-9756-5f32e4c50a5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sequence: ['новое', 'и', 'неизвестное']\n",
      "Target sequence: ['–', 'это', 'опасно']\n",
      "Predicted sequence: ['–', 'положительных', 'я']\n",
      "Input sequence: ['подведут', 'этих', 'жизненных']\n",
      "Target sequence: ['препятствий', 'никогда', 'не']\n",
      "Predicted sequence: ['на', 'что', 'не']\n",
      "Input sequence: ['помогай', 'это', 'к']\n",
      "Target sequence: ['добру', 'не', 'приведет']\n",
      "Predicted sequence: ['добру', 'опасно', 'приведет']\n",
      "Input sequence: ['настроение', 'добавляет', 'годы']\n",
      "Target sequence: ['к', 'вашей', 'жизни']\n",
      "Predicted sequence: ['к', 'в', 'только']\n",
      "Input sequence: ['вы', 'строите', 'в']\n",
      "Target sequence: ['своем', 'уме', 'никогда']\n",
      "Predicted sequence: ['вас', 'эту', 'позитивно']\n",
      "Input sequence: ['нужно', 'подняться', 'это']\n",
      "Target sequence: ['та', 'которую', 'вы']\n",
      "Predicted sequence: ['по', 'значит', 'позитивным']\n",
      "Input sequence: ['не', 'нужно', 'делать']\n",
      "Target sequence: ['то', 'что', 'делают']\n",
      "Predicted sequence: ['а', 'по', 'все']\n",
      "Input sequence: ['того', 'чтобы', 'заработать']\n",
      "Target sequence: ['миллион', '–', 'жизни']\n",
      "Predicted sequence: ['потому', 'что', 'надо']\n",
      "Input sequence: ['каждой', 'идеей', 'питающей']\n",
      "Target sequence: ['ваши', 'мечты', 'подумайте']\n",
      "Predicted sequence: ['ваши', 'мечты', 'с']\n",
      "Input sequence: ['нужен', 'вокруг', 'полно']\n",
      "Target sequence: ['более', 'молодых', 'и']\n",
      "Predicted sequence: ['внешностью', 'не', 'и']\n",
      "Input sequence: ['наших', 'ограничений', 'пусть']\n",
      "Target sequence: ['позитив', 'будет', 'вашим']\n",
      "Predicted sequence: ['других', 'чем', 'не']\n",
      "Input sequence: ['великие', 'дела', 'чудеса']\n",
      "Target sequence: ['рождаются', 'из', 'убеждений']\n",
      "Predicted sequence: ['рождаются', 'из', 'убеждений']\n",
      "Input sequence: ['к', 'успеху', 'ничто']\n",
      "Target sequence: ['не', 'делает', 'человека']\n",
      "Predicted sequence: ['создать', 'радугу', 'человека']\n",
      "Input sequence: ['понедельник', 'задают', 'тон']\n",
      "Target sequence: ['всей', 'твоей', 'неделе']\n",
      "Predicted sequence: ['смогли', 'в', 'сделать']\n",
      "Input sequence: ['этим', 'ничего', 'поделать']\n",
      "Target sequence: ['как', 'бы', 'я']\n",
      "Predicted sequence: ['не', 'этом', 'у']\n"
     ]
    }
   ],
   "source": [
    "for i in range(15):\n",
    "    inputs, targets = test_set[i]\n",
    "    inference_model_and_print(inputs, targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882bf2fb-64a3-451e-85e8-3bef0d96bf5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
